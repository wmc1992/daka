{"pages":[],"posts":[{"title":"Layer Normalize","text":"Layer Normalize打卡；","link":"/daka/2022/05/15/nlp_basis/layer_normalize/"},{"title":"打卡规则","text":"","link":"/daka/2022/05/09/%E6%89%93%E5%8D%A1%E8%A7%84%E5%88%99/%E6%89%93%E5%8D%A1%E8%A7%84%E5%88%99/"},{"title":"Batch Normalize","text":"Batch Normalize打卡；","link":"/daka/2022/05/14/nlp_basis/batch_normalize/"},{"title":"刷题打卡 - 回溯算法","text":"刷题打卡 - 回溯算法；","link":"/daka/2022/05/13/shuati/shuati_%E7%AC%AC001%E5%A4%A9/"},{"title":"Switch Transformers（第2天）","text":"Switch Transformers打卡第2天；","link":"/daka/2022/05/09/paper/switch_transformers/switch_transformers_%E7%AC%AC2%E5%A4%A9/"},{"title":"Switch Transformers（第3天）","text":"Switch Transformers打卡第3天；","link":"/daka/2022/05/10/paper/switch_transformers/switch_transformers_%E7%AC%AC3%E5%A4%A9/"},{"title":"Switch Transformers（第1天）","text":"","link":"/daka/2022/05/09/paper/switch_transformers/switch_transformers_%E7%AC%AC1%E5%A4%A9/"},{"title":"Switch Transformers（第4天）","text":"Switch Transformers打卡第4天；","link":"/daka/2022/05/11/paper/switch_transformers/switch_transformers_%E7%AC%AC4%E5%A4%A9/"},{"title":"Switch Transformers（第5天）","text":"Switch Transformers打卡第5天； 行文目录 switch transformer 模型结构； switch transformer 的训练tricks（为了获取高指标方面的tricks）； 高效训练，并行训练（为了提高训练速度方面的tricks）： 数据并行； 模型并行； 专家并行； 实验结果： 预训练阶段的实验结果； 下游任务阶段的实验结果：包括微调效果、蒸馏效果、多语言上的效果； Switch Transformer 模型结构","link":"/daka/2022/05/12/paper/switch_transformers/switch_transformers_%E7%AC%AC5%E5%A4%A9/"},{"title":"Switch Transformers（第4天-晚间）","text":"Switch Transformers打卡第4天-晚间；","link":"/daka/2022/05/11/paper/switch_transformers/switch_transformers_%E7%AC%AC4%E5%A4%A9_%E6%99%9A%E9%97%B4/"}],"tags":[{"name":"NLP算法","slug":"NLP算法","link":"/daka/tags/NLP%E7%AE%97%E6%B3%95/"},{"name":"LN","slug":"LN","link":"/daka/tags/LN/"},{"name":"打卡规则","slug":"打卡规则","link":"/daka/tags/%E6%89%93%E5%8D%A1%E8%A7%84%E5%88%99/"},{"name":"BN","slug":"BN","link":"/daka/tags/BN/"},{"name":"回溯算法","slug":"回溯算法","link":"/daka/tags/%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/"},{"name":"预训练模型","slug":"预训练模型","link":"/daka/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"},{"name":"Sparse Model","slug":"Sparse-Model","link":"/daka/tags/Sparse-Model/"},{"name":"MoE","slug":"MoE","link":"/daka/tags/MoE/"}],"categories":[{"name":"NLP算法","slug":"NLP算法","link":"/daka/categories/NLP%E7%AE%97%E6%B3%95/"},{"name":"0_打卡规则","slug":"0-打卡规则","link":"/daka/categories/0-%E6%89%93%E5%8D%A1%E8%A7%84%E5%88%99/"},{"name":"刷题","slug":"刷题","link":"/daka/categories/%E5%88%B7%E9%A2%98/"},{"name":"NLP基础","slug":"NLP算法/NLP基础","link":"/daka/categories/NLP%E7%AE%97%E6%B3%95/NLP%E5%9F%BA%E7%A1%80/"},{"name":"预训练模型","slug":"NLP算法/预训练模型","link":"/daka/categories/NLP%E7%AE%97%E6%B3%95/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"},{"name":"回溯算法","slug":"刷题/回溯算法","link":"/daka/categories/%E5%88%B7%E9%A2%98/%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/"}]}